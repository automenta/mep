# MEP: Muon Equilibrium Propagation

### ğŸ§  Biologically Plausible Deep Learning Without Backpropagation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://github.com/your-username/mep/actions/workflows/tests.yml/badge.svg)](https://github.com/your-username/mep)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

---

## ğŸ“„ Abstract

**Equilibrium Propagation (EP)** offers a biologically plausible alternative to backpropagation by estimating gradients through the contrast between two equilibrium states of an energy-based model. However, historical implementations have suffered from training instability, poor convergence, and impractical computational requirementsâ€”preventing EP from scaling to modern deep learning tasks.

We present **Spectral Dion-Muon Equilibrium Propagation (SDMEP)**, a refactored optimization framework that addresses these limitations through three key innovations:

1.  **Spectral Constraints (S):** Enforcing Ïƒ(W) â‰¤ Î³ < 1 guarantees convergence to a unique fixed point, eliminating the oscillatory divergence that plagued earlier EP implementations.
2.  **Dion Low-Rank Updates (D):** For large weight matrices, low-rank SVD with error feedback reduces computational cost while preserving gradient information in the dominant subspace.
3.  **Muon Orthogonalization (M):** Newton-Schulz iteration orthogonalizes gradients, improving conditioning and enabling stable training at greater depths.

Our framework achieves **competitive performance on MNIST benchmarks** (90.4% vs 93.8% for SGD), validates EP gradients against numerical differentiation, and reveals surprising strengths in **continual learning** (46Ã— less forgetting than SGD). SDMEP is designed as a research platform for neuromorphic computing, continual learning, and energy-efficient deep learning on analog hardware.

**Keywords:** Equilibrium Propagation, Biologically Plausible Learning, Energy-Based Models, Spectral Normalization, Low-Rank Optimization, Neuromorphic Computing, Continual Learning

---

## ğŸ“‹ Table of Contents

- [Abstract](#-abstract)
- [Introduction](#-introduction-the-backpropagation-bottleneck)
- [The MEP Framework](#-the-mep-framework)
- [Quick Start](#-quick-start)
- [Benchmark Results](#-benchmark-results)
- [Optimizer Selection Guide](#-optimizer-selection-guide)
- [Architecture: Strategy Pattern](#-architecture-strategy-pattern)
- [Understanding EP](#-understanding-ep-a-visual-guide)
- [Open Research Questions](#-open-research-questions)
- [References](#-references)

---

## ğŸŒ Introduction: The Backpropagation Bottleneck

Backpropagation has powered the deep learning revolution, but it faces fundamental limitations:

| Problem | Why It Matters |
|---------|----------------|
| **Biological Implausibility** | Requires symmetric forward/backward weights ("weight transport problem") and global error signalsâ€”neither observed in biological neural circuits. |
| **Memory Scaling** | Activation storage grows linearly with depth, limiting training of very deep networks on memory-constrained hardware. |
| **Hardware Mismatch** | Digital backpropagation is energy-inefficient on emerging analog/neuromorphic substrates (optical chips, memristor arrays). |

**Equilibrium Propagation** (Scellier & Bengio, 2017) addresses these issues by:
- Using only **local Hebbian updates** derived from an energy function
- Achieving **O(1) memory cost** independent of network depth
- Mapping naturally to **continuous-time dynamics** in analog hardware

However, vanilla EP is notoriously unstable. **SDMEP** provides the "safety harness" that makes EP practical for deep learning research.

---

## ğŸ”¬ The MEP Framework

### Theoretical Foundation

MEP is built on the theory of **Energy Based Models (EBMs)** with contractive dynamics. Given an input x and network states s = {sâ‚, ..., sâ‚—}, we define the energy:

```
E(x, s, y) = E_internal + E_external

E_internal = 0.5 Ã— Î£ ||sáµ¢ - fáµ¢(sáµ¢â‚‹â‚)||Â²     (state consistency)
E_external = Î² Ã— L(s_last, y)                (task loss)
```

**Free phase** (Î² = 0): States settle to minimize E_internal, reaching a fixed point s*.

**Nudged phase** (Î² > 0): The target y perturbs the energy landscape, yielding a new fixed point s^Î².

**EP Gradient:** The contrast (s^Î² - s*) / Î² approximates âˆ‚L/âˆ‚W without backpropagation.

### The Safety Harness: S-D-M

| Component | Purpose | Mechanism |
|-----------|---------|-----------|
| **Spectral (S)** | Stability | Power iteration enforces Ïƒ(W) â‰¤ Î³, ensuring contractive dynamics and unique fixed points. |
| **Dion (D)** | Efficiency | Low-rank SVD (U Î£ V^T) with error feedback for matrices >100K parameters. |
| **Muon (M)** | Conditioning | Newton-Schulz iteration orthogonalizes gradients: X_{k+1} = Â½ X_k (3I - X_k^T X_k). |

---

## ğŸ”§ Quick Start

### Installation

```bash
pip install -e .
```

### Basic Usage

```python
import torch.nn as nn
from mep import smep, sdmep, muon_backprop

model = nn.Sequential(
    nn.Linear(784, 256),
    nn.ReLU(),
    nn.Linear(256, 10)
)

# Option 1: EP mode (biologically plausible)
optimizer = smep(model.parameters(), model=model, mode='ep')
optimizer.step(x=x, target=y)  # No .backward() needed!

# Option 2: Backprop mode (drop-in SGD replacement)
optimizer = muon_backprop(model.parameters())
loss.backward()
optimizer.step()
```

### Recommended Configuration

```python
from mep import smep

# For classification
optimizer = smep(
    model.parameters(),
    model=model,
    lr=0.01,
    mode='ep',
    beta=0.5,
    settle_steps=10,
    settle_lr=0.05,
    loss_type='mse',
    use_error_feedback=False,  # Critical for stability
    ns_steps=5,
    gamma=0.95,
)

# For continual learning
optimizer = smep(
    model.parameters(),
    model=model,
    lr=0.01,
    mode='ep',
    beta=0.5,
    settle_steps=10,
    settle_lr=0.05,
    loss_type='mse',
    use_error_feedback=True,   # Enables memory retention
    error_beta=0.95,           # High retention
)
```

---

## ğŸ“Š Benchmark Results

### Classification (MNIST, 10 epochs, 3000 train / 500 test)

| Optimizer | Best Val Acc | Gap to SGD | Time/Epoch |
|-----------|--------------|------------|------------|
| **SGD** | 93.8% | â€” | 0.57s |
| **Adam** | 93.8% | 0.0% | 0.57s |
| **SMEP** | 90.4% | 3.4% | 1.79s |
| **Muon** | 89.0% | 4.8% | 0.67s |
| **EqProp** | 74.8% | 19.0% | 1.89s |
| **SDMEP** | 15.0%* | 78.8% | 2.06s |

*SDMEP fails on small models; Dion requires large matrices (>100K params).

**Key findings:**
- SMEP achieves 90.4% accuracyâ€”competitive for a biologically plausible optimizer
- EP is ~3Ã— slower due to settling iterations
- Error feedback causes instability in single-task classification

### Continual Learning (Average Forgetting, 4 tasks)

| Optimizer | Forgetting | Relative to SGD |
|-----------|------------|-----------------|
| **SMEP + Error Feedback** | **0.04** | **46Ã— better** |
| SMEP (no EF) | 0.47 | 4Ã— better |
| **SGD** | **1.85** | baseline |

**Key findings:**
- Error feedback dramatically reduces catastrophic forgetting
- Acts as implicit gradient replay without storing data
- Promising direction for lifelong learning applications

### Regression (Synthetic, MSE)

| Optimizer | Final MSE | Stability |
|-----------|-----------|-----------|
| **SGD** | **0.0031** | âœ… Stable |
| **Adam** | 0.0046 | âœ… Stable |
| SMEP | 4.28 | âŒ Unstable |
| SMEP+EF | 345.68 | âŒâŒ Diverges |

**Key findings:**
- EP shows severe instability on regression despite natural MSE alignment
- This is an **open research problem**

---

## ğŸ¯ Optimizer Selection Guide

| Use Case | Recommended | Configuration |
|----------|-------------|---------------|
| Standard classification | **Adam/SGD** | Default settings |
| Biological plausibility research | **SMEP** | `use_error_feedback=False` |
| Continual/lifelong learning | **SMEP+EF** | `use_error_feedback=True, error_beta=0.95` |
| Memory-constrained (deep nets) | **EP** | O(1) memory |
| Neuromorphic hardware | **SMEP/LocalEP** | Local learning rules |
| Very deep networks | **Muon** | Backprop + orthogonalization |
| Large models (>1M params/layer) | **SDMEP** | `dion_thresh=200000` |

---

## ğŸ—ï¸ Architecture: Strategy Pattern

The refactored MEP uses a **strategy pattern** for maximum flexibility and extensibility:

```
CompositeOptimizer
â”œâ”€â”€ GradientStrategy    (how to compute âˆ‡L)
â”‚   â”œâ”€â”€ BackpropGradient    # Standard .backward()
â”‚   â”œâ”€â”€ EPGradient          # Free/nudged phase contrast
â”‚   â”œâ”€â”€ LocalEPGradient     # Layer-local updates only
â”‚   â””â”€â”€ NaturalGradient     # Fisher Information whitening
â”œâ”€â”€ UpdateStrategy      (how to transform âˆ‡L â†’ Î”W)
â”‚   â”œâ”€â”€ PlainUpdate         # Vanilla SGD
â”‚   â”œâ”€â”€ MuonUpdate          # Newton-Schulz orthogonalization
â”‚   â”œâ”€â”€ DionUpdate          # Low-rank SVD for large matrices
â”‚   â””â”€â”€ FisherUpdate        # Natural gradient descent
â”œâ”€â”€ ConstraintStrategy  (how to enforce constraints)
â”‚   â”œâ”€â”€ NoConstraint        # Unconstrained
â”‚   â””â”€â”€ SpectralConstraint  # Ïƒ(W) â‰¤ Î³
â””â”€â”€ FeedbackStrategy    (how to accumulate residuals)
    â”œâ”€â”€ NoFeedback          # Standard optimization
    â””â”€â”€ ErrorFeedback       # Accumulate residuals (continual learning)
```

### Custom Composition

```python
from mep.optimizers import (
    CompositeOptimizer,
    EPGradient, MuonUpdate, SpectralConstraint, ErrorFeedback
)

# Custom optimizer for continual learning
optimizer = CompositeOptimizer(
    model.parameters(),
    gradient=EPGradient(beta=0.5, settle_steps=10),
    update=MuonUpdate(ns_steps=5),
    constraint=SpectralConstraint(gamma=0.95),
    feedback=ErrorFeedback(beta=0.95),
    lr=0.01,
    model=model,
)
```

### Debugging with EPMonitor

```python
from mep import smep, EPMonitor

monitor = EPMonitor()
optimizer = smep(model.parameters(), model=model, mode='ep')

for epoch in range(epochs):
    monitor.start_epoch()
    
    for x, y in train_loader:
        optimizer.step(x=x, target=y)
    
    metrics = monitor.end_epoch(model, optimizer)
    print(f"Epoch {epoch}: Energy gap = {metrics.energy_gap:.4f}")
    
    if not monitor.check_convergence():
        print("Warning: Settling may not have converged!")

print(monitor.summary())
```

---

## ğŸ”® Understanding EP: A Visual Guide

### Free Phase vs Nudged Phase

```
Free Phase (Î² = 0):
Input â†’ [Layer 1] â†’ [Layer 2] â†’ [Layer 3] â†’ Output
         â”‚  â–²        â”‚  â–²        â”‚  â–²
         â”‚  â”‚        â”‚  â”‚        â”‚  â”‚
         â””â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”˜
              States settle to minimize E_internal

Nudged Phase (Î² > 0):
Input â†’ [Layer 1] â†’ [Layer 2] â†’ [Layer 3] â†’ Output
         â”‚  â–²        â”‚  â–²        â”‚  â–²         â”‚
         â”‚  â”‚        â”‚  â”‚        â”‚  â”‚         â”‚ (target nudges)
         â””â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              Target perturbs energy landscape

EP Gradient = (nudged_states - free_states) / Î²
```

### Energy Function

```
E = E_internal + E_external

E_internal = 0.5 Ã— Î£ ||sáµ¢ - fáµ¢(sáµ¢â‚‹â‚)||Â²   (state consistency)
E_external = Î² Ã— L(s_last, y)             (task loss)

For classification with MSE:
  L = ||s_last - one_hot(y)||Â²

For classification with CrossEntropy:
  L = CrossEntropy(softmax(s_last), y)
```

---

## ğŸ”® Open Research Questions

### 1. Why Does Regression Fail?

Despite EP's energy function naturally matching MSE loss, we observed severe instability (MSE explodes after ~10 epochs).

**Hypotheses:**
- Settling dynamics create positive feedback loop
- Error feedback accumulates in wrong direction
- Energy landscape has poor local minima

**Potential fixes:**
- Lower settling learning rate (0.01 â†’ 0.001)
- Gradient clipping during settling
- Energy-based early stopping
- Different energy function formulation

**This is an open problemâ€”contributions welcome!**

### 2. Can We Close the Classification Gap?

SMEP achieves 90.4% vs SGD's 93.8% on MNIST. The 3.4% gap is acceptable for research but limits practical adoption.

**Potential improvements:**
- Adaptive settling (stop when energy converges) - potential 30-50% speedup
- Better energy functions for classification
- Layer-wise learning rates
- Batch normalization integration
- Deeper architecture studies

### 3. SDMEP for Large Models

Dion (low-rank SVD) should shine for large matrices but currently fails on small models (15% accuracy).

**Needed:**
- Better rank selection heuristics (adaptive based on gradient spectrum)
- Higher rank_frac for small models (0.3 â†’ 0.5+)
- Higher dion_thresh to avoid Dion on small layers

**Promise:** For models with >1M params per layer, Dion could provide significant speedup.

### 4. Neuromorphic Hardware Integration

EP's local learning rules are a natural fit for analog hardware, but no public implementations exist.

**Potential targets:**
- Optical neural networks (continuous-time dynamics)
- Memristor crossbars (local Hebbian updates)
- Spiking neural networks (event-based processing)
- Analog chips (natural fit for settling dynamics)

**This is a prime research opportunity!**

### 5. Continual Learning Mechanisms

Error feedback reduces forgetting by 46Ã—, but the mechanism is not well understood.

**Questions:**
- How much history does the buffer retain?
- Is there an optimal error_beta for different task sequences?
- Can we combine with explicit replay for even better results?
- Does this work for domain-incremental (not just task-incremental) learning?

---

## ğŸ“š References

1.  Scellier, B., & Bengio, Y. (2017). Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation. *Frontiers in Computational Neuroscience*, 11, 24.

2.  Jordan, K. (2024). The Muon Optimizer. *GitHub Repository*. https://github.com/KellerJordan/Muon

3.  Miyato, T., Kataoka, T., Koyama, M., & Yoshida, Y. (2018). Spectral Normalization for Generative Adversarial Networks. *ICLR*.

4.  Scellier, B., Franceschi, L., & Bengio, Y. (2024). Energy-Based Learning in Continuous Time. *arXiv preprint*.

5.  Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J., & Hinton, G. (2020). Backpropagation and the Brain. *Nature Reviews Neuroscience*, 21(6), 335-346.

6.  Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.

7.  Kirkpatrick, J., et al. (2017). Overcoming Catastrophic Forgetting in Neural Networks. *PNAS*, 114(13), 3521-3526.

---

## ğŸ“ Module Structure

```
mep/
â”œâ”€â”€ optimizers/
â”‚   â”œâ”€â”€ composite.py       # Main CompositeOptimizer
â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ gradient.py    # Backprop, EP, LocalEP, Natural
â”‚   â”‚   â”œâ”€â”€ update.py      # Muon, Dion, Fisher
â”‚   â”‚   â”œâ”€â”€ constraint.py  # Spectral norm
â”‚   â”‚   â””â”€â”€ feedback.py    # Error feedback
â”‚   â”œâ”€â”€ energy.py          # Energy function
â”‚   â”œâ”€â”€ settling.py        # Settling dynamics
â”‚   â”œâ”€â”€ monitor.py         # EP debugging utilities
â”‚   â””â”€â”€ inspector.py       # Model structure extraction
â”œâ”€â”€ presets/
â”‚   â””â”€â”€ __init__.py        # Factory functions (smep, sdmep, etc.)
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ tuned_compare.py   # Classification benchmarks
â”‚   â””â”€â”€ niche_benchmarks.py # Regression, continual learning
â”œâ”€â”€ cuda/
â”‚   â””â”€â”€ kernels.py         # CUDA-accelerated operations
â””â”€â”€ optimizers_legacy.py   # Archived original implementation
```

---

## ğŸ¤ Contributing

Contributions welcome! High-priority areas:

1.  **Fix regression instability** - EP should excel here
2.  **Adaptive settling** - Early stopping for 30-50% speedup
3.  **SDMEP tuning** - Better rank selection for large models
4.  **Continual learning benchmarks** - More task sequences, domains
5.  **Hardware demos** - Neuromorphic chip implementations

```bash
# Development setup
pip install -e ".[dev]"
pytest tests/ -v
```

---

## ğŸ“„ License

MIT License. See [LICENSE](LICENSE) for details.
